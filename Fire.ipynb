{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fire.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POa7NP2eo4ab"
      },
      "outputs": [],
      "source": [
        "#Creating the customized CNN architecture\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "TRAINING_DIR = \"Train\"\n",
        "training_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  horizontal_flip=True,\n",
        "                                  rotation_range=30,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  fill_mode='nearest')\n",
        "VALIDATION_DIR = \"Validation\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "train_generator = training_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                         target_size=(224,224),\n",
        "                                         class_mode='categorical',\n",
        "                                         batch_size = 64)\n",
        "validation_generator = validation_datagen.flow_from_directory(      \n",
        "                                           VALIDATION_DIR,\n",
        "                                           target_size=(224,224),\n",
        "                                           class_mode='categorical',\n",
        "                                           batch_size= 16)\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(224, 224, 3)), tf.keras.layers.MaxPooling2D(pool_size = (3,3), strides=(2,2)),\n",
        "tf.keras.layers.Conv2D(256, (5,5), activation='relu'),\n",
        "tf.keras.layers.MaxPooling2D(pool_size = (3,3), strides=(2,2)),\n",
        "tf.keras.layers.Conv2D(384, (5,5), activation='relu'),\n",
        "tf.keras.layers.MaxPooling2D(pool_size = (3,3), strides=(2,2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(2048, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.25),\n",
        "tf.keras.layers.Dense(1024, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(2, activation='softmax')])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=Adam(lr=0.0001),\n",
        "metrics=['acc'])\n",
        "history = model.fit(\n",
        "train_generator,\n",
        "steps_per_epoch = 15,\n",
        "epochs = 50,\n",
        "validation_data = validation_generator,\n",
        "validation_steps = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating customized InceptionV3 model\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "TRAINING_DIR = \"Train\"\n",
        "training_datagen = ImageDataGenerator(rescale=1./255,\n",
        "zoom_range=0.15,\n",
        "horizontal_flip=True,\n",
        "fill_mode='nearest')\n",
        "VALIDATION_DIR = \"/content/FIRE-SMOKE-DATASET/Test\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "TRAINING_DIR,\n",
        "target_size=(224,224),\n",
        "shuffle = True,\n",
        "class_mode='categorical',\n",
        "batch_size = 128)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "VALIDATION_DIR,\n",
        "target_size=(224,224),\n",
        "class_mode='categorical',\n",
        "shuffle = True,\n",
        "batch_size= 14)\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "history = model.fit(\n",
        "train_generator,\n",
        "steps_per_epoch = 14,\n",
        "epochs = 20,\n",
        "validation_data = validation_generator,\n",
        "validation_steps = 14)\n",
        "\n",
        "#To train the top 2 inception blocks, freeze the first 249 layers and unfreeze the rest.\n",
        "for layer in model.layers[:249]:\n",
        "  layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "  layer.trainable = True\n",
        "#Recompile the model for these modifications to take effect\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['acc'])\n",
        "history = model.fit(\n",
        "train_generator,\n",
        "steps_per_epoch = 14,\n",
        "epochs = 10,\n",
        "validation_data = validation_generator,\n",
        "validation_steps = 14)"
      ],
      "metadata": {
        "id": "KYCTEN84pDKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real-time Testing:\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "#Load the saved model\n",
        "model = tf.keras.models.load_model('InceptionV3.h5')\n",
        "video = cv2.VideoCapture(0)\n",
        "while True:\n",
        "        _, frame = video.read()\n",
        "#Convert the captured frame into RGB\n",
        "        im = Image.fromarray(frame, 'RGB')\n",
        "#Resizing into 224x224 because we trained the model with this image size.\n",
        "        im = im.resize((224,224))\n",
        "        img_array = image.img_to_array(im)\n",
        "        img_array = np.expand_dims(img_array, axis=0) / 255\n",
        "        probabilities = model.predict(img_array)[0]\n",
        "        #Calling the predict method on model to predict 'fire' on the image\n",
        "        prediction = np.argmax(probabilities)\n",
        "        #if prediction is 0, which means there is fire in the frame.\n",
        "        if prediction == 0:\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "                print(probabilities[prediction])\n",
        "cv2.imshow(\"Capturing\", frame)\n",
        "        key=cv2.waitKey(1)\n",
        "        if key == ord('q'):\n",
        "                break\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "AfT3hEEfpiFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0vsOSxltpTGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dQaAEjycpwMf"
      }
    }
  ]
}